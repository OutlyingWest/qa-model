\section{System Overview}
The pipeline consists of four stages: data preparation, task-specific LoRA
training, inference with validation, and evaluation. MCQ and SAQ datasets are
loaded from CSV files, split into training and validation subsets, and
tokenized with a task-specific prompt template. Two separate LoRA adapters are
trained---one per task---to keep the output formats stable and the adapters
lightweight.

\subsection{Datasets and Splits}
Table~\ref{tab:dataset} summarizes the task-specific data. Country tags are
reported using ISO-style codes; MCQ values labelled ``UK'' are mapped to
``GB'' for consistency. Validation splits are drawn at random with
val\_ratio 0.15 (MCQ) and 0.20 (SAQ). No fixed seed was set for the
split, so exact train/val membership may differ across runs.

\begin{table}[t]
  \centering
  \small
  \resizebox{\columnwidth}{!}{%
  \begin{tabular}{lrrrrr}
    \hline
    Split & Total & CN & US & IR & GB \\
    \hline
    MCQ train & 836 & 219 & 214 & 206 & 197 \\
    MCQ test  & 419 & 116 & 96  & 100 & 107 \\
    SAQ train & 1333 & 339 & 340 & 323 & 331 \\
    SAQ test  & 667 & 161 & 160 & 177 & 169 \\
    \hline
  \end{tabular}}
  \caption{Dataset card by task, split, and country counts}
  \label{tab:dataset}
\end{table}

SAQ questions include crowdsourced annotations: on average 3.95 distinct
answers with 6.4 total votes per question; the \texttt{idks} field records
\textit{idk} (708), \textit{no-answer} (415), and \textit{not-applicable} (313)
flags in the training set. These signals are retained as-is and contribute to
label noise discussed later.

During inference, the system routes MCQ questions to a log-probability scorer
and routes SAQ questions to a constrained generative path. Both modes share a
validation layer that enforces the required output format and triggers limited
retries when the response is invalid. For SAQ, retrieval augmentation can be
enabled to insert a short context before answering.

The evaluation reports accuracy overall and by country tag for MCQ/SAQ.
Section~\ref{sec:experiments} details the iterative experiments, while
Section~\ref{sec:results} consolidates the final scores.
